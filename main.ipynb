{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first start captyring video. somple code and we exit using the esc key.\n",
    "# second start object tracking using meanshift first and provide the haarcascade of frontal face features.\n",
    "# determine the area where blur is to be applied. store it in variable and provide that variable to blur function\n",
    "# next the area determined for blur is given the result of blur for application\n",
    "# display the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tracking(frame):\n",
    "#     cap = cv2.VideoCapture(0)\n",
    "\n",
    "#     ret, incoming_frame = cap.read()\n",
    "\n",
    "#     # classify facial features which are needed\n",
    "#     face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#     # \n",
    "#     face_rects = face_cascade.detectMultiScale(frame)\n",
    "\n",
    "#     # from face_rects extract the face \n",
    "#     (face_x, face_y, w, h) = tuple(face_rects[0])\n",
    "#     track_window = (face_x, face_y, w, h)\n",
    "\n",
    "#     # region of interest is the whole face rectangle. from (0,0) at top of face till end of face which is detected according to cascade \n",
    "#     # classifier method\n",
    "#     roi = frame[face_y: face_y + h, face_x: face_x + w]\n",
    "#     # convert roi to hsv for better color detection. because hsv allows for that\n",
    "#     hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "#     # create histogram of roi as is explained in docs of meanshift. because it is required . \n",
    "#     roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0,180])\n",
    "#     # normalize for all frames\n",
    "#     cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "#     term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1) # search\n",
    "#     return roi_hist, term_crit, track_window\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select default webcam as input\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # if cameras is detected, start reading from the cam\n",
    "# ret, incoming_frame = cap.read()\n",
    "\n",
    "# classify facial features which are needed\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, incoming_frame = cap.read()\n",
    "    # \n",
    "    face_rects = face_cascade.detectMultiScale(incoming_frame)\n",
    "\n",
    "    # from face_rects extract the face \n",
    "    (face_x, face_y, w, h) = tuple(face_rects[0])\n",
    "    track_window = (face_x, face_y, w, h)\n",
    "\n",
    "    # region of interest is the whole face rectangle. from (0,0) at top of face till end of face which is detected according to cascade \n",
    "    # classifier method\n",
    "    roi = incoming_frame[face_y: face_y + h, face_x: face_x + w]\n",
    "\n",
    "    # convert roi to hsv for better color detection. because hsv allows for that\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #       create histogram of roi as is explained in docs of meanshift. because it is required . \n",
    "    roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0,180])\n",
    "\n",
    "    # normalize for all frames\n",
    "    cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1) # search\n",
    "    \n",
    "    if ret == True:\n",
    "\n",
    "    \n",
    "        hsv = cv2.cvtColor(incoming_frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0,180], 1) # search\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "\n",
    "        x,y,w,h = track_window\n",
    "        cv2.rectangle(incoming_frame, (x,y), (x+w,y+h), (0,255,0), 5)\n",
    "        # determine area for blur\n",
    "        blur_area = incoming_frame[y:y+h, x:x+w]\n",
    "        # apply blur\n",
    "        blur = cv2.GaussianBlur(blur_area, (51,51), 0)\n",
    "        # provide the blur to area to be blurred\n",
    "        incoming_frame[y:y+h, x:x+w] = blur\n",
    "\n",
    "        # start display the input frames in window named \"Face Blur\"\n",
    "        cv2.imshow('Face Blur', incoming_frame)\n",
    "\n",
    "        # assign the esc key as exit button and also wait 10ms before exiting\n",
    "        k = cv2.waitKey(10) & 0xFF\n",
    "        # if esc was pressed exit from loop. i.e. close capture\n",
    "        if k == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbc768028c3e6ead51d9a200ddcb2ec858ae62844dcd1994729a8279be9b48f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
